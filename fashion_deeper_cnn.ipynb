{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      2       0       0       0       0       0       0       0       0   \n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      6       0       0       0       0       0       0       0       5   \n",
       "3      0       0       0       0       1       2       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9    ...     pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0        30        43   \n",
       "3       0    ...            3         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         1         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing data from csv files\n",
    "train_df = pd.read_csv(r'data/fashion-mnist_train.csv')\n",
    "test_df = pd.read_csv(r'data/fashion-mnist_test.csv')\n",
    "\n",
    "train_df.head() # checking if import is successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# converting data frames into numpy arrays\n",
    "train_data = np.array(train_df, dtype = 'float32')\n",
    "test_data = np.array(test_df, dtype = 'float32' )\n",
    "\n",
    "x_train = train_data[:,1:] / 255 # all rows 1: starts from column 1\n",
    "y_train = train_data[:,0]\n",
    "\n",
    "x_test = test_data[:,1:] / 255 # divide by 255 scales out pixel to 0 -1\n",
    "y_test = test_data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test size is the percent you want to split train and test 0.2 is 20% for validation\n",
    "# random_state: defines how to split data  can be left to null\n",
    "x_train, x_validate, y_train, y_validate = train_test_split(\n",
    "    x_train, y_train, test_size = 0.2, random_state = 12345\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niSL8QKIIP5Aowg8kivADifp/v40gSWQqgikAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x126eb4e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = x_train[500,:].reshape(28,28)\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the CNN\n",
    " - define the model\n",
    " - complie the model\n",
    " - fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_rows = 28\n",
    "im_cols = 28\n",
    "batch_size = 514\n",
    "im_shape = (im_rows, im_cols, 1) # 1 is for adding 3D\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], *im_shape)\n",
    "x_test = x_test.reshape(x_test.shape[0], *im_shape)\n",
    "x_validate = x_validate.reshape(x_validate.shape[0], *im_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    define a model: \n",
    "        sequential model\n",
    "    pass layer: \n",
    "        1. Conv2d(dim of output, matrix size of kernel, activation function, dim of input)\n",
    "        2. MaxPooling2D(pool size) : downsize image for this example instead of 28 it is going to be 14\n",
    "        3. Droupout: randomly dropout connections in next layer\n",
    "        \n",
    "        4. Flatten: flatten out all the layers\n",
    "        5. Dense layer for input\n",
    "        6. Dense layer for output\n",
    "        \n",
    "'''\n",
    "name = '1_Layer'\n",
    "cnn_model_1 = Sequential([\n",
    "    Conv2D(filters = 32, kernel_size=3, activation='relu', input_shape=im_shape, name='Conv2D-1'),\n",
    "    MaxPooling2D(pool_size = 2, name=\"Maxpool\"),\n",
    "    Dropout(0.2, name ='Dropout'),\n",
    "    Flatten(name='flatten'),\n",
    "    Dense(32, activation='relu',name='Dense'),\n",
    "    Dense(10, activation='softmax',name='Output')\n",
    "], name = name)\n",
    "\n",
    "name = '2_Layer'\n",
    "cnn_model_2 = Sequential([\n",
    "    Conv2D(filters = 32, kernel_size=3, activation='relu', input_shape=im_shape, name='Conv2D-1'),\n",
    "    MaxPooling2D(pool_size = 2, name=\"Maxpool\"),\n",
    "    Dropout(0.2, name ='Dropout-1'),\n",
    "    \n",
    "    Conv2D(filters = 64, kernel_size=3, activation='relu', name='Conv2D-2'),\n",
    "    Dropout(0.25, name ='Dropout-2'),\n",
    "    \n",
    "    Flatten(name='flatten'),\n",
    "    Dense(32, activation='relu',name='Dense'),\n",
    "    Dense(10, activation='softmax',name='Output')\n",
    "], name = name)\n",
    "\n",
    "name = '3_Layer'\n",
    "cnn_model_3 = Sequential([\n",
    "    Conv2D(filters = 32, kernel_size=3, activation='relu', input_shape=im_shape, name='Conv2D-1'),\n",
    "    MaxPooling2D(pool_size = 2, name=\"Maxpool\"),\n",
    "    Dropout(0.2, name ='Dropout-1'),\n",
    "    \n",
    "    Conv2D(filters = 64, kernel_size=3, activation='relu', name='Conv2D-2'),\n",
    "    Dropout(0.25, name ='Dropout-2'),\n",
    "    \n",
    "    Conv2D(filters = 128, kernel_size=3, activation='relu', name='Conv2D-3'),\n",
    "    Dropout(0.4, name ='Dropout-3'),\n",
    "    \n",
    "    Flatten(name='flatten'),\n",
    "    Dense(32, activation='relu',name='Dense'),\n",
    "    Dense(10, activation='softmax',name='Output')\n",
    "], name = name)\n",
    "\n",
    "cnn_models = [cnn_model_1, cnn_model_2, cnn_model_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv2D-1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "Maxpool (MaxPooling2D)       (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "Dropout (Dropout)            (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "Dense (Dense)                (None, 32)                173088    \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 173,738\n",
      "Trainable params: 173,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv2D-1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "Maxpool (MaxPooling2D)       (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "Dropout-1 (Dropout)          (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv2D-2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "Dropout-2 (Dropout)          (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "Dense (Dense)                (None, 32)                247840    \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 266,986\n",
      "Trainable params: 266,986\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv2D-1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "Maxpool (MaxPooling2D)       (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "Dropout-1 (Dropout)          (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv2D-2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "Dropout-2 (Dropout)          (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "Conv2D-3 (Conv2D)            (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "Dropout-3 (Dropout)          (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10368)             0         \n",
      "_________________________________________________________________\n",
      "Dense (Dense)                (None, 32)                331808    \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 424,810\n",
      "Trainable params: 424,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# cnn_model_1.summary()\n",
    "for model in cnn_models:\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/50\n",
      "48000/48000 [==============================] - 26s 533us/step - loss: 0.7869 - acc: 0.7436 - val_loss: 0.4731 - val_acc: 0.8332\n",
      "Epoch 2/50\n",
      "48000/48000 [==============================] - 23s 487us/step - loss: 0.4327 - acc: 0.8493 - val_loss: 0.3895 - val_acc: 0.8688\n",
      "Epoch 3/50\n",
      "48000/48000 [==============================] - 23s 489us/step - loss: 0.3790 - acc: 0.8667 - val_loss: 0.3511 - val_acc: 0.8817\n",
      "Epoch 4/50\n",
      "48000/48000 [==============================] - 23s 488us/step - loss: 0.3481 - acc: 0.8773 - val_loss: 0.3358 - val_acc: 0.8828\n",
      "Epoch 5/50\n",
      "48000/48000 [==============================] - 24s 494us/step - loss: 0.3289 - acc: 0.8831 - val_loss: 0.3177 - val_acc: 0.8908\n",
      "Epoch 6/50\n",
      "48000/48000 [==============================] - 23s 483us/step - loss: 0.3147 - acc: 0.8893 - val_loss: 0.3138 - val_acc: 0.8898\n",
      "Epoch 7/50\n",
      "48000/48000 [==============================] - 24s 497us/step - loss: 0.3063 - acc: 0.8922 - val_loss: 0.3055 - val_acc: 0.8944\n",
      "Epoch 8/50\n",
      "48000/48000 [==============================] - 24s 496us/step - loss: 0.2902 - acc: 0.8973 - val_loss: 0.2993 - val_acc: 0.8958\n",
      "Epoch 9/50\n",
      "48000/48000 [==============================] - 23s 489us/step - loss: 0.2811 - acc: 0.8999 - val_loss: 0.2883 - val_acc: 0.8992\n",
      "Epoch 10/50\n",
      "48000/48000 [==============================] - 24s 499us/step - loss: 0.2746 - acc: 0.9032 - val_loss: 0.2842 - val_acc: 0.8973\n",
      "Epoch 11/50\n",
      "48000/48000 [==============================] - 24s 505us/step - loss: 0.2684 - acc: 0.9039 - val_loss: 0.2805 - val_acc: 0.9024\n",
      "Epoch 12/50\n",
      "48000/48000 [==============================] - 23s 479us/step - loss: 0.2618 - acc: 0.9058 - val_loss: 0.2741 - val_acc: 0.9012\n",
      "Epoch 13/50\n",
      "48000/48000 [==============================] - 25s 518us/step - loss: 0.2539 - acc: 0.9093 - val_loss: 0.2663 - val_acc: 0.9074\n",
      "Epoch 14/50\n",
      "48000/48000 [==============================] - 25s 530us/step - loss: 0.2505 - acc: 0.9101 - val_loss: 0.2617 - val_acc: 0.9055\n",
      "Epoch 15/50\n",
      "48000/48000 [==============================] - 25s 518us/step - loss: 0.2454 - acc: 0.9120 - val_loss: 0.2706 - val_acc: 0.9010\n",
      "Epoch 16/50\n",
      "48000/48000 [==============================] - 24s 500us/step - loss: 0.2402 - acc: 0.9143 - val_loss: 0.2650 - val_acc: 0.9046\n",
      "Epoch 17/50\n",
      "48000/48000 [==============================] - 24s 492us/step - loss: 0.2337 - acc: 0.9161 - val_loss: 0.2614 - val_acc: 0.9068\n",
      "Epoch 18/50\n",
      "48000/48000 [==============================] - 22s 464us/step - loss: 0.2302 - acc: 0.9171 - val_loss: 0.2534 - val_acc: 0.9089\n",
      "Epoch 19/50\n",
      "48000/48000 [==============================] - 22s 464us/step - loss: 0.2235 - acc: 0.9194 - val_loss: 0.2517 - val_acc: 0.9113\n",
      "Epoch 20/50\n",
      "48000/48000 [==============================] - 22s 460us/step - loss: 0.2219 - acc: 0.9215 - val_loss: 0.2525 - val_acc: 0.9094\n",
      "Epoch 21/50\n",
      "48000/48000 [==============================] - 22s 462us/step - loss: 0.2179 - acc: 0.9215 - val_loss: 0.2666 - val_acc: 0.9034\n",
      "Epoch 22/50\n",
      "48000/48000 [==============================] - 22s 462us/step - loss: 0.2126 - acc: 0.9229 - val_loss: 0.2465 - val_acc: 0.9117\n",
      "Epoch 23/50\n",
      "48000/48000 [==============================] - 22s 465us/step - loss: 0.2073 - acc: 0.9249 - val_loss: 0.2496 - val_acc: 0.9096\n",
      "Epoch 24/50\n",
      "48000/48000 [==============================] - 22s 462us/step - loss: 0.2069 - acc: 0.9255 - val_loss: 0.2458 - val_acc: 0.9103\n",
      "Epoch 25/50\n",
      "48000/48000 [==============================] - 22s 468us/step - loss: 0.2024 - acc: 0.9265 - val_loss: 0.2471 - val_acc: 0.9124\n",
      "Epoch 26/50\n",
      "48000/48000 [==============================] - 22s 466us/step - loss: 0.1980 - acc: 0.9291 - val_loss: 0.2496 - val_acc: 0.9119\n",
      "Epoch 27/50\n",
      "48000/48000 [==============================] - 22s 466us/step - loss: 0.1946 - acc: 0.9299 - val_loss: 0.2411 - val_acc: 0.9153\n",
      "Epoch 28/50\n",
      "48000/48000 [==============================] - 23s 469us/step - loss: 0.1934 - acc: 0.9298 - val_loss: 0.2463 - val_acc: 0.9118\n",
      "Epoch 29/50\n",
      "48000/48000 [==============================] - 22s 467us/step - loss: 0.1917 - acc: 0.9313 - val_loss: 0.2382 - val_acc: 0.9169\n",
      "Epoch 30/50\n",
      "48000/48000 [==============================] - 22s 467us/step - loss: 0.1881 - acc: 0.9318 - val_loss: 0.2387 - val_acc: 0.9170\n",
      "Epoch 31/50\n",
      "48000/48000 [==============================] - 23s 472us/step - loss: 0.1836 - acc: 0.9343 - val_loss: 0.2548 - val_acc: 0.9123\n",
      "Epoch 32/50\n",
      "48000/48000 [==============================] - 22s 466us/step - loss: 0.1819 - acc: 0.9345 - val_loss: 0.2407 - val_acc: 0.9149\n",
      "Epoch 33/50\n",
      "48000/48000 [==============================] - 23s 470us/step - loss: 0.1804 - acc: 0.9355 - val_loss: 0.2454 - val_acc: 0.9143\n",
      "Epoch 34/50\n",
      "48000/48000 [==============================] - 23s 473us/step - loss: 0.1771 - acc: 0.9348 - val_loss: 0.2354 - val_acc: 0.9188\n",
      "Epoch 35/50\n",
      "48000/48000 [==============================] - 23s 470us/step - loss: 0.1731 - acc: 0.9375 - val_loss: 0.2384 - val_acc: 0.9168\n",
      "Epoch 36/50\n",
      "48000/48000 [==============================] - 22s 463us/step - loss: 0.1692 - acc: 0.9375 - val_loss: 0.2377 - val_acc: 0.9181\n",
      "Epoch 37/50\n",
      "48000/48000 [==============================] - 22s 467us/step - loss: 0.1674 - acc: 0.9398 - val_loss: 0.2388 - val_acc: 0.9173\n",
      "Epoch 38/50\n",
      "48000/48000 [==============================] - 22s 462us/step - loss: 0.1662 - acc: 0.9391 - val_loss: 0.2392 - val_acc: 0.9156\n",
      "Epoch 39/50\n",
      "48000/48000 [==============================] - 22s 468us/step - loss: 0.1595 - acc: 0.9424 - val_loss: 0.2414 - val_acc: 0.9176\n",
      "Epoch 40/50\n",
      "48000/48000 [==============================] - 22s 465us/step - loss: 0.1607 - acc: 0.9414 - val_loss: 0.2418 - val_acc: 0.9177\n",
      "Epoch 41/50\n",
      "48000/48000 [==============================] - 22s 462us/step - loss: 0.1585 - acc: 0.9420 - val_loss: 0.2369 - val_acc: 0.9178\n",
      "Epoch 42/50\n",
      "48000/48000 [==============================] - 22s 464us/step - loss: 0.1572 - acc: 0.9426 - val_loss: 0.2428 - val_acc: 0.9150\n",
      "Epoch 43/50\n",
      "48000/48000 [==============================] - 22s 465us/step - loss: 0.1518 - acc: 0.9446 - val_loss: 0.2366 - val_acc: 0.9189\n",
      "Epoch 44/50\n",
      "48000/48000 [==============================] - 23s 478us/step - loss: 0.1506 - acc: 0.9449 - val_loss: 0.2413 - val_acc: 0.9174\n",
      "Epoch 45/50\n",
      "48000/48000 [==============================] - 1162s 24ms/step - loss: 0.1495 - acc: 0.9457 - val_loss: 0.2414 - val_acc: 0.9174\n",
      "Epoch 46/50\n",
      "48000/48000 [==============================] - 28s 585us/step - loss: 0.1484 - acc: 0.9462 - val_loss: 0.2473 - val_acc: 0.9149\n",
      "Epoch 47/50\n",
      "48000/48000 [==============================] - 26s 547us/step - loss: 0.1481 - acc: 0.9459 - val_loss: 0.2521 - val_acc: 0.9152\n",
      "Epoch 48/50\n",
      "48000/48000 [==============================] - 22s 463us/step - loss: 0.1430 - acc: 0.9486 - val_loss: 0.2386 - val_acc: 0.9185\n",
      "Epoch 49/50\n",
      "48000/48000 [==============================] - 22s 467us/step - loss: 0.1376 - acc: 0.9508 - val_loss: 0.2434 - val_acc: 0.9178\n",
      "Epoch 50/50\n",
      "48000/48000 [==============================] - 25s 512us/step - loss: 0.1386 - acc: 0.9495 - val_loss: 0.2457 - val_acc: 0.9193\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'history_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-bbf239ec1089>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     )\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'history_dict' is not defined"
     ]
    }
   ],
   "source": [
    "history_dic = {}\n",
    "\n",
    "for model in cnn_models:\n",
    "    model.compile(\n",
    "        loss = 'sparse_categorical_crossentropy',\n",
    "        optimizer = Adam(),\n",
    "        metrics = ['accuracy']\n",
    "    )\n",
    "    \n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        batch_size = batch_size,\n",
    "        epochs = 50, verbose =1,\n",
    "        validation_data = (x_validate, y_validate)\n",
    "    )\n",
    "    \n",
    "    history_dict[model.name] = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, figsize =(8,6))\n",
    "\n",
    "for history in history_dic:\n",
    "    val_acc = history_dict[history].history['val_acc']\n",
    "    val_loss = history_dict[history].history['val_loss']\n",
    "    ax1.plot(val_acc, label = history)\n",
    "    ax1.plot(val_loss, label = history)\n",
    "    \n",
    "ax1.set_ylabel('validation accuracy')\n",
    "ax2.set_ylabel('validation loss')\n",
    "ax2.set_xlabel('epochs')\n",
    "ax1.legend()\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
